import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import time
import av
from streamlit_webrtc import webrtc_streamer, WebRtcMode

# –ö—ç—à–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    return YOLO('yolov8n-pose.pt')

model = load_model()

def get_keypoint_safe(keypoints, idx, fallback=None):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ—á–∫–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π confidence"""
    if keypoints is None or idx >= len(keypoints):
        return fallback if fallback is not None else np.array([0, 0, 0])
    point = keypoints[idx]
    if len(point) >= 3 and point[2] > 0.25:
        return point[:3]
    return fallback if fallback is not None else np.array([0, 0, 0])

def analyze_posture(image):
    """–ê–Ω–∞–ª–∏–∑ –æ—Å–∞–Ω–∫–∏ –¥–ª—è —Å–∏–¥—è—á–µ–≥–æ –ø–æ–ª–æ–∂–µ–Ω–∏—è"""
    try:
        results = model(image, verbose=False)
        
        if not results or len(results) == 0:
            return image, "–ü–æ–≤–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ –∫–∞–º–µ—Ä–µ –ª–∏—Ü–æ–º"
            
        annotated_image = results[0].plot()
        keypoints = results[0].keypoints.xy[0].cpu().numpy() if results[0].keypoints else None
        
        if keypoints is None or len(keypoints) < 6:  # –ú–∏–Ω–∏–º—É–º: –≥–æ–ª–æ–≤–∞ –∏ –ø–ª–µ—á–∏
            return annotated_image, "–í—Å—Ç–∞–Ω—å—Ç–µ —Ç–∞–∫, —á—Ç–æ–±—ã –±—ã–ª–∏ –≤–∏–¥–Ω—ã –ø–ª–µ—á–∏"
        
        # –ü–æ–ª—É—á–∞–µ–º –∫–ª—é—á–µ–≤—ã–µ —Ç–æ—á–∫–∏ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ —Ç–µ–ª–∞
        LEFT_SHOULDER = 5
        RIGHT_SHOULDER = 6
        LEFT_EAR = 3
        RIGHT_EAR = 4
        NOSE = 0
        
        ls = get_keypoint_safe(keypoints, LEFT_SHOULDER)
        rs = get_keypoint_safe(keypoints, RIGHT_SHOULDER)
        le = get_keypoint_safe(keypoints, LEFT_EAR, ls)
        re = get_keypoint_safe(keypoints, RIGHT_EAR, rs)
        nose = get_keypoint_safe(keypoints, NOSE, (ls + rs) / 2)
        
        # –ê–Ω–∞–ª–∏–∑ –æ—Å–∞–Ω–∫–∏
        messages = []
        
        # 1. –ù–∞–∫–ª–æ–Ω –≥–æ–ª–æ–≤—ã –≤–ø–µ—Ä–µ–¥
        head_forward = (nose[1] > (ls[1] + rs[1])/2 + 0.1*image.shape[0])
        if head_forward:
            messages.append("‚Ä¢ –ì–æ–ª–æ–≤–∞ –Ω–∞–∫–ª–æ–Ω–µ–Ω–∞ –≤–ø–µ—Ä–µ–¥ (—Ç–µ–∫—Å—Ç–æ–≤–∞—è —à–µ—è)")
        
        # 2. –°—É—Ç—É–ª–æ—Å—Ç—å –ø–ª–µ—á
        shoulders_rounded = (ls[0] > rs[0] + 0.1*image.shape[1]) or \
                          (rs[0] < ls[0] - 0.1*image.shape[1])
        if shoulders_rounded:
            messages.append("‚Ä¢ –ü–ª–µ—á–∏ —Å—Å—É—Ç—É–ª–µ–Ω—ã")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        if messages:
            report = [
                "**–ü—Ä–æ–±–ª–µ–º—ã —Å –æ—Å–∞–Ω–∫–æ–π (—Å–∏–¥—è):**",
                *messages,
                "\n**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**",
                "‚Ä¢ –ü–æ–¥–Ω–∏–º–∏—Ç–µ —ç–∫—Ä–∞–Ω –Ω–∞ —É—Ä–æ–≤–µ–Ω—å –≥–ª–∞–∑",
                "‚Ä¢ –û–±–æ–ø—Ä–∏—Ç–µ—Å—å –Ω–∞ —Å–ø–∏–Ω–∫—É –∫—Ä–µ—Å–ª–∞",
                "‚Ä¢ –°–ª–µ–¥–∏—Ç–µ –∑–∞ –ø–æ–ª–æ–∂–µ–Ω–∏–µ–º –≥–æ–ª–æ–≤—ã"
            ]
        else:
            report = ["**–û—Ç–ª–∏—á–Ω–∞—è –æ—Å–∞–Ω–∫–∞!**", "–í—ã –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–∏–¥–∏—Ç–µ –∑–∞ —Å—Ç–æ–ª–æ–º"]
        
        return annotated_image, "\n".join(report)
        
    except Exception as e:
        return image, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"

def video_frame_callback(frame):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–∞–¥—Ä–æ–≤ –¥–ª—è WebRTC"""
    img = frame.to_ndarray(format="bgr24")
    analyzed_img, posture_status = analyze_posture(img)
    return av.VideoFrame.from_ndarray(analyzed_img, format="bgr24")

def main():
    st.set_page_config(layout="wide")
    st.title("üì∑ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Å–∞–Ω–∫–∏ –¥–ª—è –æ—Ñ–∏—Å–∞")
    
    st.markdown("""
    ## –ò–Ω—Å—Ç—Ä—É–∫—Ü–∏—è:
    1. –°—è–¥—å—Ç–µ –∑–∞ —Ä–∞–±–æ—á–∏–π —Å—Ç–æ–ª –∫–∞–∫ –æ–±—ã—á–Ω–æ
    2. –†–∞–∑—Ä–µ—à–∏—Ç–µ –¥–æ—Å—Ç—É–ø –∫ –∫–∞–º–µ—Ä–µ
    3. –†–∞—Å–ø–æ–ª–æ–∂–∏—Ç–µ—Å—å —Ç–∞–∫, —á—Ç–æ–±—ã –±—ã–ª–∏ –≤–∏–¥–Ω—ã –ø–ª–µ—á–∏ –∏ –≥–æ–ª–æ–≤–∞
    """)
    
    # WebRTC –ø–æ—Ç–æ–∫ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ –±—Ä–∞—É–∑–µ—Ä–µ
    webrtc_ctx = webrtc_streamer(
        key="posture",
        mode=WebRtcMode.SENDRECV,
        video_frame_callback=video_frame_callback,
        media_stream_constraints={"video": True, "audio": False},
        async_processing=True,
        rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]}
    )
    
    if not webrtc_ctx.state.playing:
        st.warning("–û–∂–∏–¥–∞–Ω–∏–µ –¥–æ—Å—Ç—É–ø–∞ –∫ –∫–∞–º–µ—Ä–µ...")

if __name__ == "__main__":
    main()