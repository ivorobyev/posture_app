import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import time

# –ö—ç—à–∏—Ä—É–µ–º –∑–∞–≥—Ä—É–∑–∫—É –º–æ–¥–µ–ª–∏
@st.cache_resource
def load_model():
    return YOLO('yolov8n-pose.pt')

model = load_model()

def get_keypoint_safe(keypoints, idx, fallback=None):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ—á–∫–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π confidence"""
    if keypoints is None or idx >= len(keypoints):
        return fallback if fallback is not None else np.array([0, 0, 0])
    point = keypoints[idx]
    if len(point) >= 3 and point[2] > 0.25:  # confidence > 0.25
        return point[:3]
    return fallback if fallback is not None else np.array([0, 0, 0])

def analyze_posture(image):
    """–ê–Ω–∞–ª–∏–∑ –æ—Å–∞–Ω–∫–∏ —Å –∑–∞—â–∏—Ç–æ–π –æ—Ç –æ—à–∏–±–æ–∫"""
    try:
        results = model(image, verbose=False)
        
        if not results or len(results) == 0:
            return image, "–í—Å—Ç–∞–Ω—å—Ç–µ –ø–µ—Ä–µ–¥ –∫–∞–º–µ—Ä–æ–π"
        
        annotated_image = results[0].plot()
        keypoints = results[0].keypoints.xy[0].cpu().numpy() if results[0].keypoints else None
        
        if keypoints is None or len(keypoints) < 6:  # –ú–∏–Ω–∏–º—É–º: –≥–æ–ª–æ–≤–∞ –∏ –ø–ª–µ—á–∏
            return annotated_image, "–ü–æ–≤–µ—Ä–Ω–∏—Ç–µ—Å—å –∫ –∫–∞–º–µ—Ä–µ –ª–∏—Ü–æ–º"
        
        # COCO-—Ñ–æ—Ä–º–∞—Ç –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
        NOSE = 0
        LEFT_SHOULDER = 5
        RIGHT_SHOULDER = 6
        LEFT_EAR = 3
        RIGHT_EAR = 4
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ—á–∫–∏
        ls = get_keypoint_safe(keypoints, LEFT_SHOULDER)
        rs = get_keypoint_safe(keypoints, RIGHT_SHOULDER)
        le = get_keypoint_safe(keypoints, LEFT_EAR, ls)
        re = get_keypoint_safe(keypoints, RIGHT_EAR, rs)
        nose = get_keypoint_safe(keypoints, NOSE, (ls + rs) / 2)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–æ—á–µ–∫
        if ls[2] < 0.2 or rs[2] < 0.2:
            return annotated_image, "–í—Å—Ç–∞–Ω—å—Ç–µ –ø—Ä—è–º–æ (–ø–ª–µ—á–∏ –Ω–µ –≤–∏–¥–Ω—ã)"
        
        # –ê–Ω–∞–ª–∏–∑ –æ—Å–∞–Ω–∫–∏
        messages = []
        
        # 1. –ù–∞–∫–ª–æ–Ω –≥–æ–ª–æ–≤—ã –≤–ø–µ—Ä–µ–¥
        head_forward = (nose[1] > (ls[1] + rs[1])/2 + 0.1*image.shape[0])
        if head_forward:
            messages.append("‚Ä¢ –ì–æ–ª–æ–≤–∞ –Ω–∞–∫–ª–æ–Ω–µ–Ω–∞ –≤–ø–µ—Ä–µ–¥")
        
        # 2. –°—É—Ç—É–ª–æ—Å—Ç—å –ø–ª–µ—á
        shoulders_rounded = (ls[0] > rs[0] + 0.1*image.shape[1]) or \
                          (rs[0] < ls[0] - 0.1*image.shape[1])
        if shoulders_rounded:
            messages.append("‚Ä¢ –ü–ª–µ—á–∏ —Å—Å—É—Ç—É–ª–µ–Ω—ã")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç
        if messages:
            report = [
                "**–û–±–Ω–∞—Ä—É–∂–µ–Ω—ã –ø—Ä–æ–±–ª–µ–º—ã —Å –æ—Å–∞–Ω–∫–æ–π:**",
                *messages,
                "\n**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**",
                "‚Ä¢ –î–µ—Ä–∂–∏—Ç–µ –≥–æ–ª–æ–≤—É –ø—Ä—è–º–æ",
                "‚Ä¢ –†–∞—Å–ø—Ä–∞–≤—å—Ç–µ –ø–ª–µ—á–∏",
                "‚Ä¢ –°–ª–µ–¥–∏—Ç–µ –∑–∞ –ø–æ–ª–æ–∂–µ–Ω–∏–µ–º —Å–ø–∏–Ω—ã"
            ]
        else:
            report = ["**–û—Ç–ª–∏—á–Ω–∞—è –æ—Å–∞–Ω–∫–∞!**"]
        
        return annotated_image, "\n".join(report)
        
    except Exception as e:
        return image, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}"

def main():
    st.set_page_config(layout="wide")
    st.title("üì∑ –ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Å–∞–Ω–∫–∏")
    st.write("–≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç –≤–∞—à—É –æ—Å–∞–Ω–∫—É –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏")
    
    # –°–æ–∑–¥–∞–µ–º –¥–≤–µ –∫–æ–ª–æ–Ω–∫–∏
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("–í–∏–¥ —Å –∫–∞–º–µ—Ä—ã")
        run = st.checkbox("–í–∫–ª—é—á–∏—Ç—å –≤–µ–±-–∫–∞–º–µ—Ä—É", value=True)
        FRAME_WINDOW = st.image([])
    
    with col2:
        st.header("–ê–Ω–∞–ª–∏–∑ –æ—Å–∞–Ω–∫–∏")
        status_placeholder = st.empty()
        if not run:
            status_placeholder.markdown("""
                **–û–∂–∏–¥–∞–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö —Å –∫–∞–º–µ—Ä—ã...**
                
                –í–∫–ª—é—á–∏—Ç–µ –≤–µ–±-–∫–∞–º–µ—Ä—É –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –æ—Å–∞–Ω–∫–∏.
            """)
    
    if run:
        camera = cv2.VideoCapture(0)
        try:
            while run:
                ret, frame = camera.read()
                if not ret:
                    st.error("–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã")
                    break
                
                # –ê–Ω–∞–ª–∏–∑ –æ—Å–∞–Ω–∫–∏
                analyzed_frame, posture_status = analyze_posture(frame)
                
                # –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
                with col1:
                    FRAME_WINDOW.image(analyzed_frame, channels="BGR")
                
                with col2:
                    status_placeholder.markdown(posture_status)
                
                time.sleep(0.1)
        finally:
            camera.release()
            cv2.destroyAllWindows()

if __name__ == "__main__":
    main()