import streamlit as st
import cv2
import numpy as np
from ultralytics import YOLO
import time
from enum import Enum

class PostureType(Enum):
    STANDING = "—Å—Ç–æ—è"
    SITTING = "—Å–∏–¥—è"
    UNKNOWN = "–Ω–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"

@st.cache_resource
def load_model():
    return YOLO('yolov8n-pose.pt')

model = load_model()

def get_keypoint_safe(keypoints, idx, fallback=None):
    """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ —Ç–æ—á–∫–∏ —Å –ø—Ä–æ–≤–µ—Ä–∫–æ–π confidence"""
    if keypoints is None or idx >= len(keypoints):
        return fallback if fallback is not None else np.array([0, 0, 0])
    
    point = keypoints[idx]
    if len(point) >= 3 and point[2] > 0.25:  # –ë–æ–ª–µ–µ –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ confidence
        return point[:3]
    return fallback if fallback is not None else np.array([0, 0, 0])

def calculate_angle(a, b, c):
    """–í—ã—á–∏—Å–ª–µ–Ω–∏–µ —É–≥–ª–∞ –º–µ–∂–¥—É —Ç—Ä–µ–º—è —Ç–æ—á–∫–∞–º–∏"""
    a, b, c = np.array(a), np.array(b), np.array(c)
    ba = a - b
    bc = c - b
    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc))
    return np.degrees(np.arccos(cosine_angle))

def determine_posture_type(keypoints, img_height):
    """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –ø–æ–∑—ã (—Å—Ç–æ—è/—Å–∏–¥—è)"""
    # COCO-—Ñ–æ—Ä–º–∞—Ç –∫–ª—é—á–µ–≤—ã—Ö —Ç–æ—á–µ–∫
    LEFT_SHOULDER = 5
    RIGHT_SHOULDER = 6
    LEFT_HIP = 11
    RIGHT_HIP = 12
    LEFT_KNEE = 13
    RIGHT_KNEE = 14
    LEFT_ANKLE = 15
    RIGHT_ANKLE = 16
    
    ls = get_keypoint_safe(keypoints, LEFT_SHOULDER)
    rs = get_keypoint_safe(keypoints, RIGHT_SHOULDER)
    lh = get_keypoint_safe(keypoints, LEFT_HIP)
    rh = get_keypoint_safe(keypoints, RIGHT_HIP)
    lk = get_keypoint_safe(keypoints, LEFT_KNEE)
    rk = get_keypoint_safe(keypoints, RIGHT_KNEE)
    
    # –ï—Å–ª–∏ –≤–∏–¥–Ω–æ –∫–æ–ª–µ–Ω–∏ - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∏—Ö –ø–æ–ª–æ–∂–µ–Ω–∏–µ
    if lk[2] > 0.3 or rk[2] > 0.3:
        hip_knee_ratio = ((lh[1] - lk[1]) + (rh[1] - rk[1])) / (2 * img_height)
        if hip_knee_ratio < 0.15:  # –ö–æ–ª–µ–Ω–∏ –±–ª–∏–∑–∫–æ –∫ –±–µ–¥—Ä–∞–º
            return PostureType.SITTING
        return PostureType.STANDING
    
    # –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏, –µ—Å–ª–∏ –∫–æ–ª–µ–Ω–∏ –Ω–µ –≤–∏–¥–Ω—ã
    shoulder_hip_ratio = ((ls[1] - lh[1]) + (rs[1] - rh[1])) / (2 * img_height)
    if shoulder_hip_ratio < 0.1:  # –ü–ª–µ—á–∏ –±–ª–∏–∑–∫–æ –∫ –±–µ–¥—Ä–∞–º
        return PostureType.SITTING
    
    return PostureType.UNKNOWN

def analyze_posture(image):
    """–ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Å–∞–Ω–∫–∏ —Å —É—á–µ—Ç–æ–º —Ä–∞–∫—É—Ä—Å–∞"""
    try:
        results = model(image, verbose=False)
        
        if not results or len(results) == 0 or results[0].keypoints is None:
            return image, "–í—Å—Ç–∞–Ω—å—Ç–µ –ø–µ—Ä–µ–¥ –∫–∞–º–µ—Ä–æ–π", PostureType.UNKNOWN
        
        keypoints = results[0].keypoints.xy[0].cpu().numpy()
        annotated_image = results[0].plot()
        
        if len(keypoints) < 17:  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ—á–µ–∫ COCO
            return annotated_image, "–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Ç–æ—á–µ–∫ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞", PostureType.UNKNOWN
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –ø–æ–∑—ã
        posture_type = determine_posture_type(keypoints, image.shape[0])
        
        # –û—Å–Ω–æ–≤–Ω—ã–µ —Ç–æ—á–∫–∏ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞
        NOSE = 0
        LEFT_EAR = 3
        RIGHT_EAR = 4
        LEFT_SHOULDER = 5
        RIGHT_SHOULDER = 6
        LEFT_HIP = 11
        RIGHT_HIP = 12
        
        # –ü–æ–ª—É—á–∞–µ–º —Ç–æ—á–∫–∏ —Å fallback-–∑–Ω–∞—á–µ–Ω–∏—è–º–∏
        ls = get_keypoint_safe(keypoints, LEFT_SHOULDER)
        rs = get_keypoint_safe(keypoints, RIGHT_SHOULDER)
        lh = get_keypoint_safe(keypoints, LEFT_HIP)
        rh = get_keypoint_safe(keypoints, RIGHT_HIP)
        le = get_keypoint_safe(keypoints, LEFT_EAR, ls)
        re = get_keypoint_safe(keypoints, RIGHT_EAR, rs)
        nose = get_keypoint_safe(keypoints, NOSE, (ls + rs) / 2)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–æ—á–µ–∫
        if ls[2] < 0.2 or rs[2] < 0.2:
            return annotated_image, "–ù–µ –≤–∏–∂—É –ø–ª–µ—á–∏ - –≤—Å—Ç–∞–Ω—å—Ç–µ –ø—Ä—è–º–æ", posture_type
        
        messages = []
        
        # 1. –ê–Ω–∞–ª–∏–∑ –≥–æ–ª–æ–≤—ã (–¥–ª—è –≤—Å–µ—Ö —Ä–∞–∫—É—Ä—Å–æ–≤)
        head_forward = False
        if le[2] > 0.25 and re[2] > 0.25:  # –ï—Å–ª–∏ –≤–∏–¥–Ω—ã –æ–±–∞ —É—Ö–∞
            head_angle = calculate_angle(le[:2], nose[:2], re[:2])
            if head_angle < 150:  # –ù–∞–∫–ª–æ–Ω –≥–æ–ª–æ–≤—ã –≤–ø–µ—Ä–µ–¥
                head_forward = True
        elif nose[2] > 0.3:
            if nose[1] > (ls[1] + rs[1])/2 + 0.1*image.shape[0]:  # –ù–æ—Å –Ω–∏–∂–µ –ø–ª–µ—á
                head_forward = True
        
        if head_forward:
            messages.append("‚Ä¢ –ì–æ–ª–æ–≤–∞ –Ω–∞–∫–ª–æ–Ω–µ–Ω–∞ –≤–ø–µ—Ä–µ–¥")
        
        # 2. –ê–Ω–∞–ª–∏–∑ –ø–ª–µ—á (—Ä–∞–∑–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è —Å—Ç–æ—è/—Å–∏–¥—è)
        if posture_type == PostureType.STANDING:
            shoulder_angle = calculate_angle(ls[:2], (ls+rs)[:2]/2, rs[:2])
            if shoulder_angle < 160:  # –û–∫—Ä—É–≥–ª–µ–Ω–∏–µ –ø–ª–µ—á
                messages.append("‚Ä¢ –ü–ª–µ—á–∏ —Å—Å—É—Ç—É–ª–µ–Ω—ã")
        else:
            if abs(ls[0] - rs[0]) < 0.15*image.shape[1]:  # –ü–ª–µ—á–∏ —Å–≤–µ–¥–µ–Ω—ã
                messages.append("‚Ä¢ –ü–ª–µ—á–∏ —Å–≤–µ–¥–µ–Ω—ã –≤–ø–µ—Ä–µ–¥")
        
        # 3. –ê–Ω–∞–ª–∏–∑ –ø–æ–∑–≤–æ–Ω–æ—á–Ω–∏–∫–∞
        if lh[2] > 0.3 and rh[2] > 0.3:
            spine_angle = calculate_angle((ls+rs)[:2]/2, (lh+rh)[:2]/2, 
                                        (lh+rh)[:2]/2 + np.array([0, 100]))
            if spine_angle < 75 or spine_angle > 105:
                messages.append("‚Ä¢ –ò—Å–∫—Ä–∏–≤–ª–µ–Ω–∏–µ –ø–æ–∑–≤–æ–Ω–æ—á–Ω–∏–∫–∞")
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º –æ—Ç—á–µ—Ç —Å —É—á–µ—Ç–æ–º —Ç–∏–ø–∞ –ø–æ–∑—ã
        if messages:
            report = [
                f"**–ü–æ–∑–∞ {posture_type.value} - –ø—Ä–æ–±–ª–µ–º—ã:**",
                *messages,
                "\n**–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏:**",
                "‚Ä¢ –î–µ—Ä–∂–∏—Ç–µ –≥–æ–ª–æ–≤—É –ø—Ä—è–º–æ" if head_forward else "",
                "‚Ä¢ –†–∞—Å–ø—Ä–∞–≤—å—Ç–µ –ø–ª–µ—á–∏" if "–ü–ª–µ—á–∏" in "\n".join(messages) else "",
                "‚Ä¢ –í—ã–ø—Ä—è–º–∏—Ç–µ —Å–ø–∏–Ω—É" if "–ø–æ–∑–≤–æ–Ω–æ—á–Ω–∏–∫–∞" in "\n".join(messages) else ""
            ]
            report = [r for r in report if r]  # –£–¥–∞–ª—è–µ–º –ø—É—Å—Ç—ã–µ —Å—Ç—Ä–æ–∫–∏
        else:
            report = [f"**–û—Ç–ª–∏—á–Ω–∞—è –æ—Å–∞–Ω–∫–∞ ({posture_type.value})!**"]
        
        return annotated_image, "\n".join(report), posture_type
        
    except Exception as e:
        return image, f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}", PostureType.UNKNOWN

def main():
    st.set_page_config(layout="wide")
    st.title("üì∑ –£–º–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –æ—Å–∞–Ω–∫–∏")
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è
    if 'camera_on' not in st.session_state:
        st.session_state.camera_on = False
    
    # –ö–Ω–æ–ø–∫–∞ –≤–∫–ª—é—á–µ–Ω–∏—è –∫–∞–º–µ—Ä—ã
    if not st.session_state.camera_on:
        col1, col2 = st.columns([1, 1])
        with col1:
            if st.button("–í–∫–ª—é—á–∏—Ç—å –∫–∞–º–µ—Ä—É", type="primary"):
                st.session_state.camera_on = True
                st.rerun()
        with col2:
            st.info("–î–ª—è –ª—É—á—à–µ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –≤—Å—Ç–∞–Ω—å—Ç–µ/—Å—è–¥—å—Ç–µ —Ç–∞–∫, —á—Ç–æ–±—ã –±—ã–ª–æ –≤–∏–¥–Ω–æ –ø–ª–µ—á–∏ –∏ –±–µ–¥—Ä–∞")
        return
    
    # –û—Å–Ω–æ–≤–Ω–æ–π –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.header("–í–∏–¥–µ–æ —Å –∫–∞–º–µ—Ä—ã")
        frame_placeholder = st.empty()
    
    with col2:
        st.header("–ê–Ω–∞–ª–∏–∑ –æ—Å–∞–Ω–∫–∏")
        status_placeholder = st.empty()
        posture_placeholder = st.empty()
        
        if st.button("–í—ã–∫–ª—é—á–∏—Ç—å –∫–∞–º–µ—Ä—É"):
            st.session_state.camera_on = False
            st.rerun()
            return
    
    # –†–∞–±–æ—Ç–∞ —Å –∫–∞–º–µ—Ä–æ–π
    cap = cv2.VideoCapture(0)
    try:
        while st.session_state.camera_on:
            ret, frame = cap.read()
            if not ret:
                st.error("–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è –∫ –∫–∞–º–µ—Ä–µ")
                break
            
            # –ê–Ω–∞–ª–∏–∑ –∏ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            analyzed, status, posture = analyze_posture(frame)
            frame_placeholder.image(analyzed, channels="BGR")
            status_placeholder.markdown(status)
            posture_placeholder.markdown(f"**–¢–µ–∫—É—â–∞—è –ø–æ–∑–∞:** {posture.value}")
            
            time.sleep(0.1)
    finally:
        cap.release()

if __name__ == "__main__":
    main()